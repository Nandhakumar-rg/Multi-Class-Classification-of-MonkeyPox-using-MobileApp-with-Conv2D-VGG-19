# -*- coding: utf-8 -*-
"""Copy of Copy of MonkeyPox CNN.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/100DVoFmByVo3Q_35nsJlhvKU6gJGcf0A
"""

from google.colab import drive
drive.mount('/content/drive')

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive

mkdir CNN

# Commented out IPython magic to ensure Python compatibility.
# %cd /content/drive/MyDrive/CNN

import os
# os.environ['KAGGLE_USERNAME'] = "nandhakumar5321" # username from the json file
# os.environ['KAGGLE_KEY'] = "cd3f45b0f739ad624b963b7c66bce959" # key from the json file
# !kaggle datasets download -d sachinkumar413/monkeypox-images-dataset # api copied from kaggle

from zipfile import ZipFile

file_name = "/content/drive/MyDrive/CNN/archive (3).zip"

with ZipFile(file_name, 'r') as zip:
  zip.extractall()
  print('done')

import warnings
import os
warnings.filterwarnings('ignore')
# Get all the paths
data_dir_list = os.listdir('/content/drive/MyDrive/CNN/dataset')
print(data_dir_list)
path, dirs, files = next(os.walk("/content/drive/MyDrive/CNN/dataset"))
file_count = len(files)
# print(file_count)

# Make new base directory
original_dataset_dir = '/content/drive/MyDrive/CNN/'
base_dir = '/content/drive/MyDrive/CNN/datapox'
os.mkdir(base_dir)

#create two folders (train and validation)
train_dir = os.path.join(base_dir, 'train')
os.mkdir(train_dir)

validation_dir = os.path.join(base_dir, 'validation')
os.mkdir(validation_dir)

#Under train folder create five folders
# ('chickenpox', 'cowpox', 'healthy', 'measles', 'monkeypox', 'smallpox')

train_chickenpox_dir = os.path.join(train_dir, 'chickenpox')
os.mkdir(train_chickenpox_dir)

train_cowpox_dir = os.path.join(train_dir, 'cowpox')
os.mkdir(train_cowpox_dir)

train_healthy_dir = os.path.join(train_dir, 'healthy')
os.mkdir(train_healthy_dir)

train_measles_dir = os.path.join(train_dir, 'measles')
os.mkdir(train_measles_dir)

train_monkeypox_dir = os.path.join(train_dir, 'monkeypox')
os.mkdir(train_monkeypox_dir)

train_smallpox_dir = os.path.join(train_dir, 'smallpox')
os.mkdir(train_smallpox_dir)


#Under validation folder create five folders
# ('chickenpox', 'cowpox', 'healthy', 'measles', 'monkeypox', 'smallpox')

validation_chickenpox_dir = os.path.join(validation_dir, 'chickenpox')
os.mkdir(validation_chickenpox_dir)

validation_cowpox_dir = os.path.join(validation_dir, 'cowpox')
os.mkdir(validation_cowpox_dir)

validation_healthy_dir = os.path.join(validation_dir, 'healthy')
os.mkdir(validation_healthy_dir)

validation_measles_dir = os.path.join(validation_dir, 'measles')
os.mkdir(validation_measles_dir)

validation_monkeypox_dir = os.path.join(validation_dir, 'monkeypox')
os.mkdir(validation_monkeypox_dir)

validation_smallpox_dir = os.path.join(validation_dir, 'smallpox')
os.mkdir(validation_smallpox_dir)

def split_data(SOURCE, TRAINING, VALIDATION, SPLIT_SIZE):
    files = []
    for filename in os.listdir(SOURCE):
        file = SOURCE + filename
        if os.path.getsize(file) > 0:
            files.append(filename)
        else:
            print(filename + " is zero length, so ignoring.")

    training_length = int(len(files) * SPLIT_SIZE)
    valid_length = int(len(files) - training_length)
    shuffled_set = random.sample(files, len(files))
    training_set = shuffled_set[0:training_length]
    valid_set = shuffled_set[training_length:]

    for filename in training_set:
        this_file = SOURCE + filename
        destination = TRAINING + filename
        copyfile(this_file, destination)

    for filename in valid_set:
        this_file = SOURCE + filename
        destination = VALIDATION + filename
        copyfile(this_file, destination)

CHICKENPOX_SOURCE_DIR = '/content/drive/MyDrive/CNN/dataset/chickenpox/'
TRAINING_CHICKENPOX_DIR = '/content/drive/MyDrive/CNN/datapox/train/chickenpox/'
VALID_CHICKENPOX_DIR = '/content/drive/MyDrive/CNN/datapox/validation/chickenpox/'

COWPOX_SOURCE_DIR = '/content/drive/MyDrive/CNN/dataset/cowpox/'
TRAINING_COWPOX_DIR = '/content/drive/MyDrive/CNN/datapox/train/cowpox/'
VALID_COWPOX_DIR = '/content/drive/MyDrive/CNN/datapox/validation/cowpox/'

HEALTHY_SOURCE_DIR = '/content/drive/MyDrive/CNN/dataset/healthy/'
TRAINING_HEALTHY_DIR = '/content/drive/MyDrive/CNN/datapox/train/healthy/'
VALID_HEALTHY_DIR = '/content/drive/MyDrive/CNN/datapox/validation/healthy/'

MEASLES_SOURCE_DIR = '/content/drive/MyDrive/CNN/dataset/measles/'
TRAINING_MEASLES_DIR = '/content/drive/MyDrive/CNN/datapox/train/measles/'
VALID_MEASLES_DIR = '/content/drive/MyDrive/CNN/datapox/validation/measles/'

MONKEYPOX_SOURCE_DIR = '/content/drive/MyDrive/CNN/dataset/monkeypox/'
TRAINING_MONKEYPOX_DIR = '/content/drive/MyDrive/CNN/datapox/train/monkeypox/'
VALID_MONKEYPOX_DIR = '/content/drive/MyDrive/CNN/datapox/validation/monkeypox/'

SMALLPOX_SOURCE_DIR = '/content/drive/MyDrive/CNN/dataset/smallpox/'
TRAINING_SMALLPOX_DIR = '/content/drive/MyDrive/CNN/datapox/train/smallpox/'
VALID_SMALLPOX_DIR = '/content/drive/MyDrive/CNN/datapox/validation/smallpox/'

import os
import random
from shutil import copyfile

split_size = .85

split_data(CHICKENPOX_SOURCE_DIR, TRAINING_CHICKENPOX_DIR, VALID_CHICKENPOX_DIR, split_size)
split_data(COWPOX_SOURCE_DIR, TRAINING_COWPOX_DIR, VALID_COWPOX_DIR, split_size)
split_data(HEALTHY_SOURCE_DIR, TRAINING_HEALTHY_DIR, VALID_HEALTHY_DIR, split_size)
split_data(MEASLES_SOURCE_DIR, TRAINING_MEASLES_DIR, VALID_MEASLES_DIR, split_size)
split_data(MONKEYPOX_SOURCE_DIR, TRAINING_MONKEYPOX_DIR, VALID_MONKEYPOX_DIR, split_size)
split_data(SMALLPOX_SOURCE_DIR, TRAINING_SMALLPOX_DIR, VALID_SMALLPOX_DIR, split_size)

import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib.image import imread
import pathlib

image_folder = ['chickenpox', 'cowpox', 'healthy', 'measles', 'monkeypox', 'smallpox']
nimgs = {}
for i in image_folder:
    nimages = len(os.listdir('/content/drive/MyDrive/CNN/datapox/train/'+i+'/'))
    nimgs[i]=nimages
plt.figure(figsize=(9, 6))
plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')
plt.xticks(range(len(nimgs)), list(nimgs.keys()))
plt.title('Distribution of different classes in Training Dataset')
plt.show()

for i in ['chickenpox', 'cowpox', 'healthy', 'measles', 'monkeypox', 'smallpox']:
    print('Training {} images are: '.format(i)+str(len(os.listdir('/content/drive/MyDrive/CNN/datapox/train/'+i+'/'))))

image_folder = ['chickenpox', 'cowpox', 'healthy', 'measles', 'monkeypox', 'smallpox']
nimgs = {}
for i in image_folder:
    nimages = len(os.listdir('/content/drive/MyDrive/CNN/datapox/validation/'+i+'/'))
    nimgs[i]=nimages
plt.figure(figsize=(9, 6))
plt.bar(range(len(nimgs)), list(nimgs.values()), align='center')
plt.xticks(range(len(nimgs)), list(nimgs.keys()))
plt.title('Distribution of different classes in Validation Dataset')
plt.show()

for i in ['chickenpox', 'cowpox', 'healthy', 'measles', 'monkeypox', 'smallpox']:
    print('Valid {} images are: '.format(i)+str(len(os.listdir('/content/drive/MyDrive/CNN/datapox/validation/'+i+'/'))))

from tensorflow.keras.optimizers import Adam
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout
from tensorflow.keras.models import Sequential
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
from keras.preprocessing.image import ImageDataGenerator

img_width=256; img_height=256
batch_size=32

TRAINING_DIR = '/content/drive/MyDrive/CNN/datapox/train'

train_datagen = ImageDataGenerator(rescale = 1/255.0,
                                   rotation_range=30,
                                   zoom_range=0.4,
                                   horizontal_flip=True)

train_generator = train_datagen.flow_from_directory(TRAINING_DIR,
                                                    batch_size=batch_size,
                                                    class_mode='categorical',
                                                    target_size=(img_height, img_width))

VALIDATION_DIR = '/content/drive/MyDrive/CNN/datapox/validation'

validation_datagen = ImageDataGenerator(rescale = 1/255.0)

validation_generator = validation_datagen.flow_from_directory(VALIDATION_DIR,
                                                              batch_size=batch_size,
                                                              class_mode='categorical',
                                                              target_size=(img_height, img_width)
                                                             )

callbacks = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='auto')
# autosave best Model
best_model_file = '/content/drive/MyDrive/CNN/CNN_aug_best_weights.h5'
best_model = ModelCheckpoint(best_model_file, monitor='val_acc', verbose = 1, save_best_only = True)

model = Sequential([
    Conv2D(16, (3, 3), activation='relu', input_shape=(img_height, img_width, 3)), MaxPooling2D(2, 2),
    Conv2D(32, (3, 3), activation='relu'), MaxPooling2D(2, 2),
    Conv2D(64, (3, 3), activation='relu'),
    Conv2D(64, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(128, (3, 3), activation='relu'),
    Conv2D(128, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Conv2D(256, (3, 3), activation='relu'),
    Conv2D(256, (3, 3), activation='relu'),
    Conv2D(256, (3, 3), activation='relu'),
    MaxPooling2D(2, 2),
    Flatten(),
    Dense(512, activation='relu'),
    Dense(512, activation='relu'),
    Dense(6, activation='softmax')
])
model.summary()

model.compile(optimizer='Adam',
              loss='categorical_crossentropy',
              metrics =['accuracy'])

history = model.fit_generator(train_generator,
                              epochs=5,
                              verbose=1,
                              validation_data=validation_generator,
                              callbacks = [best_model]
                              )

model.save('/content/drive/MyDrive/CNN/dest.h5')

from tensorflow.python import keras
import tensorflow

modelnew = keras.models.load_model('/content/drive/MyDrive/CNN/dest.h5')
converter=tensorflow.lite.TFLiteConverter.from_keras_model(modelnew)
tflite_model = converter.convert()
open("converted_model.tflite", "wb").write(tflite_model)

acc=history.history['accuracy']
val_acc=history.history['val_accuracy']
loss=history.history['loss']
val_loss=history.history['val_loss']

epochs=range(len(acc))

fig = plt.figure(figsize=(14,7))
plt.plot(epochs, acc, 'r', label="Training Accuracy")
plt.plot(epochs, val_acc, 'b', label="Validation Accuracy")
plt.xlabel('Epoch')
plt.ylabel('Accuracy')
plt.title('Training and validation accuracy')
plt.legend(loc='lower right')
plt.show()

fig2 = plt.figure(figsize=(14,7))
plt.plot(epochs, loss, 'r', label="Training Loss")
plt.plot(epochs, val_loss, 'b', label="Validation Loss")
plt.legend(loc='upper right')
plt.xlabel('Epoch')
plt.ylabel('Loss')
plt.title('Training and validation loss')

## Test Performance on Test Data
import pandas as pd
import numpy as np
from keras.preprocessing.image import load_img, img_to_array

def preprocess_image(path):
    img = load_img(path, target_size = (img_height, img_width))
    a = img_to_array(img)
    a = np.expand_dims(a, axis = 0)
    a /= 255.
    return a

from PIL import Image

"""Step 4. Checking performance on Test Data (Out of the sample)"""

# Read Test Images Dir and their labels
test_images_dir = '/content/drive/MyDrive/CNN/dataset/test/'
test_df = pd.read_csv('/content/drive/MyDrive/CNN/test.csv')

# put them in a list
test_dfToList = test_df['ImageID'].tolist()
test_ids = [str(item) for item in test_dfToList]

test_images = [test_images_dir+item for item in test_ids]
test_preprocessed_images = np.vstack([preprocess_image(fn) for fn in test_images])
np.save('/content/drive/MyDrive/CNN/test_preproc_CNN.npy', test_preprocessed_images)

array = model.predict(test_preprocessed_images, batch_size=1, verbose=1)
answer = np.argmax(array, axis=1)
print(answer)

test_df = pd.read_csv('/content/drive/MyDrive/CNN/test.csv')
y_true = test_df['Label']
y_pred = array
print(y_true)
print(y_pred)

from sklearn.metrics import log_loss
loss = log_loss(y_true, y_pred, eps=1e-15, normalize=True, sample_weight=None, labels=None)

from sklearn.metrics import confusion_matrix
conf_mat = confusion_matrix(y_true, answer)
conf_mat

train_dir = '/content/drive/MyDrive/CNN/datapox/train/'
classes = os.listdir(train_dir)

import itertools
def plot_confusion_matrix(cm, classes,
                          normalize=False,
                          title='Confusion matrix',
                          cmap=plt.cm.Reds):
    """
    This function prints and plots the confusion matrix.
    Normalization can be applied by setting `normalize=True`.
    """
    plt.imshow(cm, interpolation='nearest', cmap=cmap)
    plt.title(title)
    plt.colorbar()
    tick_marks = np.arange(len(classes))
    plt.xticks(tick_marks, classes, rotation=45)
    plt.yticks(tick_marks, classes)

    if normalize:
        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
        cm = cm.round(2)
        #print("Normalized confusion matrix")
    else:
        cm=cm
        #print('Confusion matrix, without normalization')

    #print(cm)

    thresh = cm.max() / 2.
    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
        plt.text(j, i, cm[i, j],
                 horizontalalignment="center",
                 color="white" if cm[i, j] > thresh else "black")

    plt.tight_layout()
    plt.ylabel('True label')
    plt.xlabel('Predicted label')

np.set_printoptions(precision=2)

fig1 = plt.figure(figsize=(7,6))
plot_confusion_matrix(conf_mat, classes=classes, title='Confusion matrix, without normalization')
plt.show()
